{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam zeichnen\n",
    "In diesem Notebook verwenden wir einen Handdetektor von MediaPipe sowie eine Webcam, um ein Bild zu zeichnen. MediaPipe bietet eine Reihe von Anwendungen im Bereich des maschinellen Lernens. Für weitere Informationen zu MediaPipe google das Projekt oder besuchen die MediaPipe Github Seite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schritt 1:** Einbinden von Bibliotheken, um bestimmte Aufgaben ausführen zu können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schritt 2:** Erstellen eines hand_detector-Objekts sowie eines webcam-Objekts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung des Handdetektors aus Mediapipe\n",
    "hand_detector = mediapipe.solutions.hands.Hands()\n",
    "\n",
    "# Einen image_counter einrichten, um die Anzahl der angezeigten Bilder zu zählen\n",
    "image_counter = 0\n",
    "\n",
    "# Eine Bildvariable für die Leinwand erstellen\n",
    "canvas_image = None\n",
    "\n",
    "# Ein Webcam-Objekt aus der Webcam mit der ID „0“ erstellen\n",
    "camera_id = 0\n",
    "webcam = cv2.VideoCapture(camera_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schritt 3:** Verwenden des Handdetektors, um ein Bild mit Ihrer Hand zu zeichnen:\n",
    "* Drücke **q**, um die Bildklassifizierung zu beenden und die Kamera zu deaktivieren.\n",
    "* Drücke **s**, um das Bild der Leinwand zu speichern.\n",
    "* Drücke **x**, um das Bild auf der Leinwand zurückzusetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starte eine while-Schleife, die so lange läuft, wie die Bedingung „True“ (wahr) ist. \n",
    "# In diesem Fall läuft die Schleife unendlich lange, wenn sie nicht mit „break“ gestoppt wird.\n",
    "while True:\n",
    "    \n",
    "    # Versuche ein Bild von der Webcam zu bekommen.\n",
    "    # Bei Erfolg wird dies in der Variable „success“ und das Bild in der variable „image“ gespeichert.\n",
    "    success, image = webcam.read()\n",
    "    \n",
    "    # Spiegeln des Bildes, sodass es wie in einem Spiegel richtig angezeigt wird\n",
    "    image = cv2.flip(image, 1)\n",
    "    \n",
    "    if canvas_image is None:\n",
    "        canvas_image = np.zeros_like(image)\n",
    "    \n",
    "    # Ausgeben einer Erfolgsmeldung wenn das Bild erfolgreich erhalten wurde\n",
    "    print(\"Wurde das Bild erfolgreich erhalten? ->\", success)\n",
    "    \n",
    "    # Anhalten der Schleife („break“), wenn das Bild nicht erfolgreich empfangen wurde.\n",
    "    # Dies ist der Fall, wenn die Variable success „False“ (falsch) ist\n",
    "    if success == False:\n",
    "        break\n",
    "    \n",
    "    # Ausgeben des aktuellen Zählerstands\n",
    "    print(\"Bildnummer anzeigen:\", image_counter)\n",
    "    \n",
    "    # Handerkennung mit KI (mit Hilfe der Mediapipe-Bibliothek)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hand_detector.process(image_rgb)\n",
    "    print(results.multi_hand_landmarks)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mediapipe.solutions.drawing_utils.draw_landmarks(image_rgb, hand_landmarks)\n",
    "            \n",
    "            finger_zero_x = int(hand_landmarks.landmark[8].x * canvas_image.shape[1])\n",
    "            finger_zero_y = int(hand_landmarks.landmark[8].y * canvas_image.shape[0])\n",
    "            \n",
    "            image_rgb = cv2.drawMarker(image_rgb, (finger_zero_x, finger_zero_y), (0,255,0), cv2.MARKER_STAR, 15, 2)\n",
    "            canvas_image = cv2.drawMarker(canvas_image, (finger_zero_x, finger_zero_y), (0,255,0), cv2.MARKER_DIAMOND, 3, 2)\n",
    "    \n",
    "    # Anzeigen des empfangenen Bildes in einem Fenster\n",
    "    cv2.imshow(\"Zeichne etwas!\", canvas_image)\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Handdetektor\", image_bgr)\n",
    "    \n",
    "    # Auf unbestimmte Zeit auf einen Tastendruck auf der Tastatur warten.\n",
    "    # Wenn die Taste gedrückt wird, die gedrückte Taste in der Variablen „pressed_key“ speichern und fortgefahren\n",
    "    pressed_key = cv2.waitKey(1)\n",
    "    \n",
    "    # Wenn die gedrückte Taste die Taste q war, wird die Schleife angehalten.\n",
    "    if pressed_key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # Wenn die gedrückte Taste die Taste s war, wird ein Bild der Leinwand gespeichert.\n",
    "    if pressed_key == ord(\"s\"):\n",
    "        cv2.imwrite(\"zeichnung.png\", canvas_image)\n",
    "    \n",
    "    # Wenn die gedrückte Taste die X-Taste war, wird das Leinwandbild zurückgesetzt.\n",
    "    if pressed_key == ord(\"x\"):\n",
    "        canvas_image = None\n",
    "    \n",
    "    # 1 zum Bildzähler addieren, um das Bild zu zählen\n",
    "    image_counter = image_counter + 1\n",
    "\n",
    "\n",
    "# Kamera deaktivieren und Fenster schließen\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvintro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
